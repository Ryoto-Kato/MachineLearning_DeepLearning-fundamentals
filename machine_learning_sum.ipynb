{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dev = torchvision.datasets.MNIST('./data', train=True, download = True)\n",
    "mnist_test = torchvision.datasets.MNIST('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mnist_dev)\n",
    "type(mnist_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev = mnist_dev.data/255.0\n",
    "print(x_dev.shape)\n",
    "y_dev = mnist_dev.targets\n",
    "print(y_dev.shape)\n",
    "mnist_dev.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable tensor(4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable tensor(9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"lable\", y_dev[i])\n",
    "    plt.imshow(x_dev[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that setting 'train=True' gives you the development set\n",
    "We need to split dev_data into the training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([50000, 784])\n"
     ]
    }
   ],
   "source": [
    "ntrain = 50_000\n",
    "print(x_dev.shape)\n",
    "x_train, y_train = x_dev[:ntrain].flatten(1), y_dev[:ntrain]\n",
    "print(x_train.shape)\n",
    "x_val, y_val = x_dev[ntrain:].flatten(1), y_dev[ntrain:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier initialization\n",
    "### !!!Do not forget reguries_grad_()\n",
    "- Variance of the weight should be 1/n to preserve input's variance after applying affine operations\n",
    "- Var(Score) = N*Var(weight)*Var(inputs)\n",
    "- If weight is initialized by Uniform distribution, we could do by\n",
    "    - Uniform(-np.sqrt(6/fan_in + fan_out), np.sqrt(6/fan_in + fan_out))\n",
    "- If weight is initialized by Normal distribution, we could do by\n",
    "    - Normal(0, 1/n)\n",
    "    - Normal(0, 2/n) if the activation function is ReLU\n",
    "    - Standard deviation = np.sqrt(2/fan_in+fan_out)\n",
    "    - When we use torch.randn(normal distribution),\n",
    "        - weight = torch.randn(fan_in, fan_out)*np.sqrt(2/fan_in+fan_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.1120,  4.6156,  0.4263,  ...,  0.4955,  1.4580,  2.6269],\n",
      "        [-1.3109, -0.2778,  2.6110,  ...,  2.8340,  6.6461,  0.6363],\n",
      "        [-0.9617,  3.2356, -3.7092,  ..., -1.3345,  0.6734,  2.8935],\n",
      "        ...,\n",
      "        [ 0.9939,  4.1211, -4.1510,  ...,  0.3182,  0.7409, -0.2717],\n",
      "        [ 1.8062,  0.9611,  1.9633,  ...,  0.9473,  0.2148,  2.2677],\n",
      "        [-4.6787,  0.2510, -0.4594,  ...,  1.1160, -0.2753,  1.5061]],\n",
      "       requires_grad=True)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "num_features = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "weight = torch.randn(num_features, num_classes) * np.sqrt(2/num_features+num_classes)\n",
    "weight.requires_grad_()\n",
    "bias = torch.zeros(num_classes, requires_grad=True)\n",
    "print(weight)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([1, 1, 1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(weight.shape)\n",
    "w = torch.randn([1, 1, 10, 10])\n",
    "print(w.squeeze().shape) ## shrink one dimentions which has one\n",
    "print(w.unsqueeze(0).shape) # expand dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input):\n",
    "    return log_softmax(input @ weight + bias)\n",
    "def log_softmax(input):\n",
    "    return input - input.exp().sum(-1).log().unsqueeze(-1)\n",
    "def nll_loss(output,target):\n",
    "    return -output[range(target.shape[0]), target].mean()\n",
    "loss_fn = nll_loss\n",
    "\n",
    "def get_accuracy(output, target):\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    return (pred == target).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input = x_train[:batch_size]\n",
    "target = y_train[:batch_size]\n",
    "pred = model(x_train[:batch_size])\n",
    "loss = loss_fn(pred, target)\n",
    "accuracy = get_accuracy(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(0.1406)\n",
      "tensor(inf, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_sample = torch.argmax(pred[0], dim=-1)\n",
    "sample_target = target[0]\n",
    "print(pred_sample)\n",
    "print(sample_target)\n",
    "print(accuracy)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47.2259, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.functional.cross_entropy combins log_softmax and negative log likelihood\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weight + bias\n",
    "\n",
    "loss_fc = F.cross_entropy\n",
    "pred = model(input)\n",
    "loss = loss_fc(pred, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(inf, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(nll_loss(log_softmax(pred), target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_features, num_classes) * np.sqrt(2/(num_features + num_classes)))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_classes))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input @ self.weight + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4019, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "pred = model.forward(x_train[:ntrain])\n",
    "print(nll_loss(log_softmax(pred), y_train[:ntrain]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntrain = #train data samples\n",
    "# batch_size = batch size\n",
    "# loss_fc = F.cross_entropy\n",
    "def train(model, num_epochs, learning_rate):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(int(np.ceil(ntrain/batch_size))): ## number of samples in minibatch\n",
    "            # Get mini_batch\n",
    "            start_i = i*batch_size\n",
    "            end_i = min(start_i + batch_size, ntrain)\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "\n",
    "            # Get prediction\n",
    "            pred = model(xb)\n",
    "\n",
    "            # Get loss\n",
    "            loss = loss_fc(pred, yb)\n",
    "            \n",
    "            # get gradient\n",
    "            model.zero_grad() # reset gradient of loss function wrt parameters\n",
    "            loss.backward() # compute gradients by backpropagation\n",
    "\n",
    "            # Optimization\n",
    "            with torch.no_grad():\n",
    "                for param in model.parameters():\n",
    "                    param -= learning_rate * param.grad\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9079)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "train(model, num_epochs=10, learning_rate=0.01)\n",
    "pred = log_softmax(model(x_val))\n",
    "accuracy = get_accuracy(pred, y_val)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "test = x_val[0].reshape(28,28)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(3), array(8), array(6), array(9), array(6), array(4), array(5), array(5), array(8), array(4)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "num_images = 10\n",
    "image = []\n",
    "fig = plt.figure(figsize=(10., 10.))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(2, 5), axes_pad=0.5)\n",
    "preds = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    pred1 = torch.argmax(pred[i], dim=-1).numpy()\n",
    "    gt = y_val[i]\n",
    "    image.append(x_val[i].reshape(28,28))\n",
    "    preds.append(pred1)\n",
    "\n",
    "counter = 0\n",
    "print(preds)\n",
    "\n",
    "for ax, im in zip(grid, image):\n",
    "    ax.set_title(str(preds[counter]))\n",
    "    ax.imshow(im, cmap=\"gray\")\n",
    "    counter = counter + 1\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.lin(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.xavier_normal_(module.weight)\n",
    "        module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc tensor(0.9375)\n",
      "train_loss tensor(0.3300, grad_fn=<NllLossBackward0>)\n",
      "val_acc tensor(0.0938)\n",
      "val_loss tensor(6.0597, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "model.apply(initialize_weight)\n",
    "\n",
    "train(model, num_epochs=10, learning_rate=0.01)\n",
    "\n",
    "loss_func_val = F.cross_entropy\n",
    "\n",
    "train_target = y_train[:batch_size]\n",
    "pred_train =model(x_train[:batch_size])\n",
    "loss_train = loss_func_val(pred_train, train_target)\n",
    "acc_train = get_accuracy(pred_train, train_target)\n",
    "\n",
    "val_target = y_train[:batch_size]\n",
    "pred_val = model(x_val[:batch_size])\n",
    "loss_val = loss_func_val(pred_val, val_target)\n",
    "acc_val = get_accuracy(pred_val, val_target)\n",
    "\n",
    "print(\"train_acc\", acc_train)\n",
    "print(\"train_loss\", loss_train)\n",
    "\n",
    "print(\"val_acc\", acc_val)\n",
    "print(\"val_loss\", loss_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(int(np.ceil(len(x_train)/batch_size))):\n",
    "            start_i = i * batch_size\n",
    "            end_i = min(start_i+batch_size, len(x_train))\n",
    "            xb=x_train[start_i:end_i]\n",
    "            yb=y_train[start_i:end_i]\n",
    "\n",
    "            #prediction\n",
    "            pred = model(xb)\n",
    "\n",
    "            #evaluate loss\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "\n",
    "            #obtain gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #update params\n",
    "            optimizer.step()\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "model.apply(initialize_weight)\n",
    "\n",
    "train(model, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataset, data_name=\"\"):\n",
    "    if isinstance(dataset, torch.utils.data.TensorDataset):\n",
    "        xb, targets = dataset[:]\n",
    "        pred = model(xb)\n",
    "    else:\n",
    "        print(\"should be Tensordataset\")\n",
    "    loss = F.cross_entropy(pred, targets)\n",
    "    acc = get_accuracy(pred, targets)\n",
    "    print(data_name)\n",
    "    print(\"loss:\" , loss)\n",
    "    print(\"accuracy\", acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_set = TensorDataset(x_train, y_train)\n",
    "val_set = TensorDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "loss: tensor(2.4375, grad_fn=<NllLossBackward0>)\n",
      "accuracy tensor(0.1122)\n",
      "\n",
      "valdation\n",
      "loss: tensor(2.4343, grad_fn=<NllLossBackward0>)\n",
      "accuracy tensor(0.1118)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation(model, train_set, data_name=\"train\")\n",
    "validation(model, val_set, data_name=\"valdation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_set = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight1(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.xavier_normal_(module.weight)\n",
    "        module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_set, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(int(len(train_set)/batch_size)):\n",
    "            #get minibatch\n",
    "            start_i = i * batch_size\n",
    "            end_i = min(start_i+batch_size, len(train_set))\n",
    "            xb, yb = train_set[start_i:end_i]\n",
    "            # print(xb.shape)\n",
    "            #prediction\n",
    "            pred = model(xb)\n",
    "\n",
    "            #loss\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "\n",
    "            #obtain derivatives\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #update parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "model.apply(initialize_weight1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model, optimizer, train_set, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "loss: tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
      "accuracy tensor(0.8640)\n",
      "\n",
      "validation\n",
      "loss: tensor(0.5661, grad_fn=<NllLossBackward0>)\n",
      "accuracy tensor(0.8600)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = TensorDataset(x_train[:1000], y_train[:1000])\n",
    "val_set = TensorDataset(x_val[:1000], y_val[:1000])\n",
    "\n",
    "validation(model, train_set, data_name=\"train\")\n",
    "validation(model, val_set, data_name=\"validation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "- You can create a DataLoader for any Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader=DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader=DataLoader(val_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)\n",
    "for xb, yb in train_loader:\n",
    "    # print(len(xb))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for input, target in train_dataloader:\n",
    "            #Generate prediction\n",
    "            pred = model(input)\n",
    "\n",
    "            #loss\n",
    "            loss = F.cross_entropy(pred, target)\n",
    "\n",
    "            #calculate gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #update paramteres\n",
    "            optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "model.apply(initialize_weight1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train(model, optimizer, train_loader, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "loss: tensor(1.5086, grad_fn=<NllLossBackward0>)\n",
      "accuracy tensor(0.6613)\n",
      "\n",
      "validation\n",
      "loss: tensor(1.4874, grad_fn=<NllLossBackward0>)\n",
      "accuracy tensor(0.6776)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = TensorDataset(x_train, y_train)\n",
    "validation_set = TensorDataset(x_val, y_val)\n",
    "validation(model, train_set, data_name=\"train\")\n",
    "validation(model, validation_set, data_name=\"validation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "- Since we do not need backpropagation for the validation set, we can use 2x large batches. NO NEED TO BE SHUFFLE For vallidation data. \n",
    "- We should shuffle training data to avoid correlation between batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(x_train, y_train)\n",
    "validation_set = TensorDataset(x_val, y_val)\n",
    "\n",
    "dataloaders={}\n",
    "dataloaders['train']=DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "dataloaders['val']=DataLoader(validation_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.train() and model.eval()\n",
    "- since batch_normalization or dropout layers are behaving different way in train and evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloaders, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for input, target in dataloaders['train']:\n",
    "            #prediction\n",
    "            pred = model(input)\n",
    "            #loss\n",
    "            loss = F.cross_entropy(pred, target)\n",
    "            #gradient\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #update\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for input, target in dataloaders['val']:\n",
    "            #prediction\n",
    "            pred = model(input)\n",
    "            #loss\n",
    "            # print(pred.shape)\n",
    "            loss += F.cross_entropy(pred, target).sum()\n",
    "            n_correct += (pred.argmax(-1)==target).sum()\n",
    "            n_samples += len(target)\n",
    "        avg_loss = loss / len(dataloaders['val'])\n",
    "        accuracy = n_correct / n_samples\n",
    "\n",
    "        print(f\"Epoch {epoch}: loss={avg_loss:.3f} accuracy={accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.405 accuracy=0.895\n",
      "Epoch 1: loss=0.350 accuracy=0.906\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(num_features=28*28, num_classes=10)\n",
    "model.apply(initialize_weight1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model, optimizer, dataloaders, num_epochs=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "- convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output size\n",
    "def output_size(input_size, kernel_size, stride, padding, layers=0):\n",
    "    out=input_size\n",
    "    for i in range(layers):\n",
    "        out= np.floor((out+(2*padding) - kernel_size)/stride) + 1\n",
    "    return int(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size(28, 3, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1, num_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2=nn.Conv2d(num_channels, num_channels, kernel_size=3,stride=2, padding=1)\n",
    "        self.conv3=nn.Conv2d(num_channels, num_classes, kernel_size=3, stride=2, padding=1)\n",
    "        # self.dense=nn.Linear(num)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 1, 28, 28)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        x = x.squeeze()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "torch.Size([3, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "test = x_train[1:4]\n",
    "print(test.shape)\n",
    "print(test.view(-1, 1, 28, 28).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 28, 28])\n",
      "torch.Size([6000, 28, 28])\n",
      "torch.Size([6000, 28, 28])\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(num_channels=16, num_classes=10)\n",
    "counter = 0\n",
    "\n",
    "size_train = int(np.floor(x_dev.shape[0] * 0.8))\n",
    "size_val = int(np.floor(x_dev.shape[0] * 0.1))\n",
    "size_test = int(np.floor(x_dev.shape[0] * 0.1))\n",
    "\n",
    "x_train, y_train = x_dev[:size_train], y_dev[:size_train]\n",
    "x_val, y_val = x_dev[size_train:size_train+size_val], y_dev[size_train:size_train+size_val]\n",
    "start_idx = size_train+size_val\n",
    "x_test, y_test = x_dev[start_idx:start_idx+size_test], y_dev[start_idx:start_idx+size_test]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(x_train.shape[0] + x_val.shape[0] + x_test.shape[0])\n",
    "\n",
    "train_set = TensorDataset(x_train, y_train)\n",
    "val_set = TensorDataset(x_val, y_val)\n",
    "test_set = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "Dataloaders = {}\n",
    "Dataloaders['train']=train_loader\n",
    "Dataloaders['val']=val_loader\n",
    "Dataloaders['test']=test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in Dataloaders['train']:\n",
    "    pred = cnn(xb)    \n",
    "    break\n",
    "print(pred.shape)\n",
    "print(pred.squeeze().shape)\n",
    "print(torch.argmax(pred.squeeze(), dim=-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.491 accuracy=0.848\n",
      "Epoch 1: loss=0.293 accuracy=0.909\n"
     ]
    }
   ],
   "source": [
    "model = CNN(num_channels=128, num_classes=10)\n",
    "model.apply(initialize_weight1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "train(model, optimizer=optimizer, dataloaders=Dataloaders, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.3411,  0.3688,  0.3726],\n",
       "            [ 0.1811,  0.0621,  0.1080],\n",
       "            [ 0.0176, -0.1174, -0.1043]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1987, -0.1692, -0.1828],\n",
       "            [-0.1203, -0.0030, -0.1076],\n",
       "            [-0.1036,  0.0140,  0.0732]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0335,  0.0082, -0.0421],\n",
       "            [ 0.0215, -0.0348,  0.0097],\n",
       "            [-0.0298, -0.1041,  0.0502]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.2244, -0.1199, -0.1831],\n",
       "            [-0.0912, -0.1366, -0.2004],\n",
       "            [-0.1848, -0.1214, -0.0520]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0085, -0.0054,  0.0471],\n",
       "            [-0.0010, -0.0551, -0.0373],\n",
       "            [-0.0354, -0.0407,  0.0628]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0109, -0.0359, -0.0251],\n",
       "            [ 0.0075, -0.0282,  0.0440],\n",
       "            [-0.0502, -0.0143, -0.0375]]]], requires_grad=True)),\n",
       " ('conv1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 2.6972e-02,  3.2710e-01, -1.4445e-03,  1.5753e-01,  1.0366e-01,\n",
       "          -1.7216e-02, -8.9492e-04, -2.2001e-02,  2.3338e-01, -3.6801e-03,\n",
       "           3.8300e-01, -2.7645e-03, -1.7285e-03,  2.6343e-01,  1.1210e-05,\n",
       "          -2.2339e-03, -8.5693e-04,  3.0125e-03,  8.1601e-03, -1.3435e-03,\n",
       "           3.3635e-03, -3.7511e-04,  8.8807e-03, -1.8120e-03, -9.8504e-04,\n",
       "           3.7969e-01, -5.0402e-03, -3.8995e-04, -1.5260e-03,  1.0079e+00,\n",
       "          -1.6114e-03, -3.4954e-03,  3.0760e-04, -3.0276e-02,  2.1119e-03,\n",
       "          -5.9132e-05,  3.8561e-04, -1.9766e-03, -2.7630e-03,  2.5919e-01,\n",
       "           8.3904e-02, -1.2349e-03, -7.1592e-04,  6.6821e-02,  2.3468e-03,\n",
       "           1.7499e-01, -1.9363e-02, -1.1617e-03, -1.3383e-03, -1.9368e-02,\n",
       "           5.2609e-02, -1.1552e-04, -7.8899e-04,  1.0530e-03, -8.4917e-04,\n",
       "           1.0109e-01, -2.5265e-03, -3.8736e-03, -7.1914e-04, -4.6304e-02,\n",
       "           3.1879e-05, -4.4733e-04, -2.0847e-03, -2.0388e-03,  2.3338e-02,\n",
       "           5.0213e-02,  1.7823e-01, -3.9205e-04, -7.0351e-03, -1.6942e-03,\n",
       "           2.1714e-03,  8.1600e-03, -1.1346e-03, -2.2167e-04,  1.3166e-04,\n",
       "          -1.5801e-03,  3.5013e-02,  1.0220e-02,  1.3067e-02, -2.5519e-04,\n",
       "          -2.7358e-02,  2.8466e-03, -1.5470e-03, -1.7105e-03, -1.7347e-03,\n",
       "          -1.4396e-03, -9.0717e-04,  1.8371e-01,  1.8165e-02,  4.0712e-03,\n",
       "          -6.9691e-04,  4.8872e-02, -1.5889e-03, -1.2625e-03, -1.6491e-03,\n",
       "           5.2260e-02,  5.0334e-01, -6.5014e-05, -1.0100e-03, -1.2644e-03,\n",
       "          -3.2750e-03,  5.6922e-04, -2.5056e-02,  6.9693e-01,  9.5024e-02,\n",
       "          -4.4941e-04, -2.0276e-02,  6.8886e-01,  4.0139e-01, -1.8109e-03,\n",
       "          -3.6094e-03, -1.0025e-03, -2.5354e-03,  3.6017e-03,  6.0641e-02,\n",
       "           6.3237e-04,  1.0411e-01, -4.6438e-04,  2.9522e-02,  2.1977e-02,\n",
       "          -1.1847e-03,  1.6123e-05, -1.5830e-03, -7.5698e-04,  5.5702e-03,\n",
       "           5.2164e-01, -5.2893e-04, -4.1869e-03], requires_grad=True)),\n",
       " ('conv2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0072,  0.0250,  0.0680],\n",
       "            [-0.0117,  0.0089,  0.0012],\n",
       "            [ 0.0324,  0.0005, -0.0063]],\n",
       "  \n",
       "           [[-0.0606,  0.0267, -0.0048],\n",
       "            [ 0.0193, -0.0308, -0.0416],\n",
       "            [-0.0004, -0.0311, -0.0126]],\n",
       "  \n",
       "           [[-0.0318,  0.0134, -0.0087],\n",
       "            [-0.0726, -0.0300,  0.0157],\n",
       "            [-0.0244,  0.0072, -0.0174]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0031,  0.0089, -0.0092],\n",
       "            [-0.0049, -0.0418, -0.0495],\n",
       "            [-0.0398,  0.0073, -0.1064]],\n",
       "  \n",
       "           [[ 0.0101,  0.0096,  0.0082],\n",
       "            [-0.0382,  0.0065,  0.0236],\n",
       "            [ 0.0308,  0.0187,  0.0249]],\n",
       "  \n",
       "           [[-0.0400, -0.0236, -0.0174],\n",
       "            [-0.0182, -0.0182, -0.0095],\n",
       "            [-0.0212,  0.0409,  0.0412]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0484, -0.0231, -0.0128],\n",
       "            [ 0.0138, -0.0309, -0.0299],\n",
       "            [ 0.0013, -0.0410,  0.0271]],\n",
       "  \n",
       "           [[ 0.0040,  0.0344, -0.0036],\n",
       "            [ 0.0007,  0.0364, -0.0233],\n",
       "            [-0.0467, -0.0520,  0.0330]],\n",
       "  \n",
       "           [[ 0.0418,  0.0505, -0.0091],\n",
       "            [-0.0508,  0.0184, -0.0193],\n",
       "            [ 0.0056, -0.0325, -0.0384]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0381,  0.0250, -0.0125],\n",
       "            [-0.0426, -0.0124,  0.0241],\n",
       "            [-0.0020, -0.0628, -0.0514]],\n",
       "  \n",
       "           [[ 0.0326,  0.0035, -0.0085],\n",
       "            [ 0.0342,  0.0159,  0.0098],\n",
       "            [-0.0428,  0.0051,  0.0042]],\n",
       "  \n",
       "           [[-0.0005,  0.0212, -0.0362],\n",
       "            [-0.0264, -0.0113,  0.0209],\n",
       "            [-0.0017,  0.0700,  0.0318]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0349,  0.0077, -0.0020],\n",
       "            [-0.0336, -0.0252, -0.0188],\n",
       "            [-0.0880, -0.0295,  0.0055]],\n",
       "  \n",
       "           [[-0.0214, -0.0314, -0.0149],\n",
       "            [-0.0227, -0.0120,  0.0182],\n",
       "            [-0.0313,  0.0056,  0.0409]],\n",
       "  \n",
       "           [[ 0.0025,  0.0680,  0.0045],\n",
       "            [ 0.0333, -0.0286,  0.0373],\n",
       "            [ 0.0143, -0.0195,  0.0048]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0348, -0.0134, -0.0460],\n",
       "            [ 0.0375,  0.0250, -0.0117],\n",
       "            [-0.0277,  0.0582, -0.0177]],\n",
       "  \n",
       "           [[-0.0359,  0.0229,  0.0099],\n",
       "            [ 0.0206, -0.0197,  0.0195],\n",
       "            [ 0.0511, -0.0240, -0.0010]],\n",
       "  \n",
       "           [[ 0.0032,  0.0261,  0.0046],\n",
       "            [ 0.0170, -0.0253,  0.0255],\n",
       "            [-0.0248, -0.0225, -0.0141]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.0029,  0.0052, -0.0284],\n",
       "            [-0.0476, -0.0476,  0.0376],\n",
       "            [-0.0335, -0.0578, -0.0026]],\n",
       "  \n",
       "           [[ 0.0042, -0.0123, -0.0107],\n",
       "            [ 0.0145,  0.0096,  0.0233],\n",
       "            [-0.0231,  0.0150, -0.0370]],\n",
       "  \n",
       "           [[ 0.0401,  0.0030,  0.0859],\n",
       "            [-0.0111,  0.0341, -0.0180],\n",
       "            [-0.0472, -0.0211, -0.0366]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0642, -0.0111, -0.0043],\n",
       "            [ 0.0290,  0.0214,  0.0109],\n",
       "            [-0.0117, -0.0354, -0.0580]],\n",
       "  \n",
       "           [[-0.0573,  0.0168,  0.0070],\n",
       "            [ 0.0285,  0.0106,  0.0065],\n",
       "            [-0.0347,  0.0082,  0.0525]],\n",
       "  \n",
       "           [[-0.0112, -0.0302,  0.0221],\n",
       "            [ 0.0707,  0.0038,  0.0268],\n",
       "            [ 0.0033, -0.0802, -0.0336]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0424,  0.0135,  0.0012],\n",
       "            [-0.0288,  0.0240, -0.0483],\n",
       "            [-0.0225,  0.0158,  0.0072]],\n",
       "  \n",
       "           [[ 0.0022, -0.0041,  0.0082],\n",
       "            [ 0.0134, -0.0534, -0.0179],\n",
       "            [ 0.0375,  0.0439,  0.0078]],\n",
       "  \n",
       "           [[-0.0183,  0.0224,  0.0102],\n",
       "            [-0.0172, -0.0130, -0.0086],\n",
       "            [-0.0199,  0.0443,  0.0171]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0046,  0.0163, -0.0452],\n",
       "            [ 0.0168,  0.0039,  0.0044],\n",
       "            [ 0.0074,  0.0255, -0.0877]],\n",
       "  \n",
       "           [[ 0.0011, -0.0446, -0.0424],\n",
       "            [-0.0117,  0.0133, -0.0609],\n",
       "            [-0.0135, -0.0386,  0.0056]],\n",
       "  \n",
       "           [[-0.0531, -0.0665, -0.0230],\n",
       "            [-0.0140,  0.0219,  0.0426],\n",
       "            [ 0.0214,  0.0208, -0.0176]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0351, -0.0355, -0.0015],\n",
       "            [ 0.0206,  0.0327, -0.0230],\n",
       "            [-0.0036,  0.0105,  0.0165]],\n",
       "  \n",
       "           [[-0.0174, -0.0188, -0.0140],\n",
       "            [ 0.0217, -0.0406,  0.0311],\n",
       "            [ 0.0025, -0.0170, -0.0102]],\n",
       "  \n",
       "           [[-0.0044,  0.0049,  0.0059],\n",
       "            [-0.0033,  0.0274,  0.0049],\n",
       "            [ 0.0169, -0.0127,  0.0013]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0321, -0.0347, -0.0417],\n",
       "            [ 0.0043, -0.0147,  0.0110],\n",
       "            [-0.0127,  0.0048,  0.0461]],\n",
       "  \n",
       "           [[ 0.0180,  0.0180,  0.0243],\n",
       "            [ 0.0540,  0.0721, -0.0284],\n",
       "            [-0.0127, -0.0244, -0.0223]],\n",
       "  \n",
       "           [[ 0.0238,  0.0370, -0.0175],\n",
       "            [ 0.0105, -0.0293,  0.0361],\n",
       "            [-0.0220,  0.0102,  0.0513]]]], requires_grad=True)),\n",
       " ('conv2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-2.8269e-03, -2.1980e-02, -4.9865e-02, -4.1455e-03, -4.7059e-02,\n",
       "           7.4343e-03, -9.0237e-03, -8.8914e-02,  6.3549e-02, -4.7846e-03,\n",
       "          -9.8268e-02, -2.6870e-02, -6.6367e-03, -1.5244e-02,  7.6137e-02,\n",
       "          -2.1152e-02, -9.4070e-02, -9.9523e-02,  1.3070e-01,  3.9906e-03,\n",
       "          -3.1676e-04,  4.3344e-03, -1.0173e-01,  5.1876e-02, -8.9650e-03,\n",
       "           7.7758e-02,  4.0668e-02,  9.8454e-02,  7.5787e-03, -7.1201e-02,\n",
       "          -5.0519e-03, -6.4151e-02,  9.2280e-03,  1.3571e-01, -6.1441e-02,\n",
       "          -3.0484e-03, -1.8297e-01, -5.1117e-02, -3.9374e-02, -3.9016e-02,\n",
       "           1.6597e-01, -4.2261e-02,  1.1535e-02,  1.1453e-02, -2.8416e-02,\n",
       "          -1.4774e-02, -5.0109e-02,  3.5966e-02, -7.3894e-02, -5.2610e-02,\n",
       "           3.5659e-02, -1.7185e-01, -4.4499e-03, -8.3102e-02,  4.6138e-02,\n",
       "          -9.2168e-02,  2.7468e-03, -6.7655e-02, -7.0476e-03, -5.5892e-02,\n",
       "           2.5248e-02, -1.3938e-02,  6.6082e-02, -8.5394e-02, -8.5435e-02,\n",
       "           6.8483e-02, -5.9457e-02, -1.9826e-02,  1.3014e-02, -6.3976e-02,\n",
       "           1.1028e-01,  5.3892e-02, -3.6287e-02, -4.6000e-03, -3.8952e-02,\n",
       "          -2.3242e-03,  2.2107e-01, -2.0300e-01, -4.1798e-02, -2.4466e-04,\n",
       "           2.6547e-01,  5.6868e-03,  3.2269e-01, -2.3556e-02, -1.7248e-02,\n",
       "          -8.9659e-02, -3.8415e-02, -1.4068e-02, -2.6943e-02, -2.0401e-02,\n",
       "          -5.3658e-02,  4.2245e-01, -4.4771e-02, -4.3432e-02, -2.3327e-02,\n",
       "           9.2641e-02,  4.7683e-02,  1.0329e-02, -3.5747e-02,  1.2328e-01,\n",
       "          -5.8041e-02,  4.8149e-02,  7.3369e-02, -1.5462e-02, -2.2082e-02,\n",
       "           1.5771e-01, -6.0282e-02,  5.0572e-03, -7.7101e-02, -6.5751e-02,\n",
       "          -5.2875e-02, -5.8804e-03, -2.9422e-03,  8.9366e-03, -4.6303e-02,\n",
       "          -5.2180e-02,  1.3482e-01, -4.5564e-02, -1.2337e-02, -8.3745e-02,\n",
       "          -5.2540e-02, -2.9596e-02, -9.8794e-02, -9.5866e-03,  2.1917e-01,\n",
       "          -4.2505e-02, -8.4975e-03,  2.8117e-02], requires_grad=True)),\n",
       " ('conv3.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 1.5968e-01,  1.7566e-01,  7.9112e-02],\n",
       "            [-2.2458e-02, -1.1182e-01,  1.9195e-01],\n",
       "            [-1.1117e-01,  3.9720e-02, -8.4998e-02]],\n",
       "  \n",
       "           [[-1.2690e-02,  7.2787e-02,  1.1332e-02],\n",
       "            [ 3.6860e-01,  1.4631e-01,  1.8749e-01],\n",
       "            [ 1.2693e-01, -1.0445e-02,  9.8644e-02]],\n",
       "  \n",
       "           [[-1.1531e-02, -1.6392e-02, -9.4861e-02],\n",
       "            [-6.0593e-02, -4.6771e-02, -7.8429e-02],\n",
       "            [ 4.6437e-02,  5.3194e-02,  4.2968e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-7.6409e-02, -2.3312e-01,  2.1353e-03],\n",
       "            [-7.3794e-02,  7.1441e-02, -2.0396e-02],\n",
       "            [ 5.5408e-02, -2.3859e-02,  2.4111e-02]],\n",
       "  \n",
       "           [[ 4.6486e-02, -3.7042e-02,  8.7467e-02],\n",
       "            [-3.3893e-02,  2.1199e-01, -1.1324e-01],\n",
       "            [ 1.1475e-01, -6.3823e-02,  2.1909e-02]],\n",
       "  \n",
       "           [[ 1.7831e-03, -1.0354e-01, -3.7677e-02],\n",
       "            [ 3.0983e-02, -7.0106e-02,  3.2822e-02],\n",
       "            [ 1.2852e-01,  9.4239e-02,  1.1075e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[-2.4182e-01,  1.7933e-01, -1.8489e-01],\n",
       "            [-2.7514e-01,  1.8716e-02, -2.2058e-01],\n",
       "            [ 2.8190e-01,  5.7339e-02, -2.2250e-01]],\n",
       "  \n",
       "           [[-1.2618e-01, -1.2314e-02,  6.1916e-02],\n",
       "            [-1.9361e-01,  1.1707e-01,  1.1748e-02],\n",
       "            [-4.7000e-02,  8.3565e-02,  2.6086e-02]],\n",
       "  \n",
       "           [[-1.8546e-02, -5.7662e-02, -5.3843e-02],\n",
       "            [-4.7976e-04,  5.0748e-03,  6.5729e-02],\n",
       "            [-2.5434e-02, -9.1605e-03, -7.0575e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-6.7909e-02, -1.5393e-01, -8.5360e-02],\n",
       "            [ 2.3306e-02, -9.8302e-02, -3.3660e-02],\n",
       "            [-8.5629e-02, -6.2518e-02, -7.8294e-02]],\n",
       "  \n",
       "           [[-3.8965e-03, -1.6469e-02, -7.9414e-02],\n",
       "            [-2.0465e-02,  2.6987e-02, -8.2865e-02],\n",
       "            [ 1.0307e-01, -7.8636e-02,  6.7261e-02]],\n",
       "  \n",
       "           [[-2.2534e-01,  1.6463e-02, -9.8547e-02],\n",
       "            [-3.0856e-01, -2.1511e-01,  9.8029e-03],\n",
       "            [ 1.6855e-01,  6.6175e-02, -1.0137e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[-3.5524e-01, -9.3607e-02, -1.8262e-01],\n",
       "            [-3.7617e-02,  3.3052e-02, -1.3229e-01],\n",
       "            [ 1.9136e-01,  1.3228e-01,  1.2800e-01]],\n",
       "  \n",
       "           [[-2.8412e-02,  4.3733e-02,  7.4750e-02],\n",
       "            [-1.6807e-01, -4.2688e-02, -3.3006e-03],\n",
       "            [-1.3142e-01,  5.5885e-02,  1.7328e-02]],\n",
       "  \n",
       "           [[ 4.6160e-02, -6.3776e-02, -1.0824e-01],\n",
       "            [ 3.3427e-02,  3.6922e-02,  3.7753e-02],\n",
       "            [ 7.8671e-03, -1.3784e-01, -4.0659e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.4288e-01,  2.4269e-01,  1.0990e-01],\n",
       "            [-7.5149e-02, -2.3798e-01, -5.6759e-02],\n",
       "            [ 1.0373e-01, -5.1044e-02, -7.9823e-02]],\n",
       "  \n",
       "           [[ 1.3842e-01,  8.8432e-02, -9.5063e-02],\n",
       "            [ 1.0610e-01, -3.6250e-02,  1.1626e-01],\n",
       "            [ 5.2959e-02, -2.6134e-02, -9.9605e-04]],\n",
       "  \n",
       "           [[-1.2609e-02,  1.9298e-02, -1.7295e-01],\n",
       "            [-6.6261e-02, -1.0628e-01, -9.6661e-02],\n",
       "            [ 2.1621e-01,  1.7220e-01,  1.4109e-01]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-3.1467e-03,  3.5628e-02, -2.5696e-02],\n",
       "            [-1.4922e-01,  5.1750e-02, -2.5010e-02],\n",
       "            [-6.2992e-02, -8.8604e-02, -1.1908e-01]],\n",
       "  \n",
       "           [[-7.8807e-03,  5.7154e-02,  6.9749e-02],\n",
       "            [ 7.9856e-02,  1.4898e-01,  1.0589e-01],\n",
       "            [-9.3987e-02, -3.9060e-02,  3.7362e-02]],\n",
       "  \n",
       "           [[ 1.0771e-01, -2.5909e-03,  1.0721e-01],\n",
       "            [ 6.8790e-02,  4.4234e-02,  1.2070e-01],\n",
       "            [ 1.7885e-02,  5.9253e-02, -3.7740e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-8.7287e-02, -5.8373e-03,  3.3694e-02],\n",
       "            [-6.2493e-02,  1.0046e-01,  9.0377e-02],\n",
       "            [-3.0456e-01, -1.8718e-01, -2.1647e-01]],\n",
       "  \n",
       "           [[ 1.2825e-01, -1.2869e-03,  8.4060e-02],\n",
       "            [ 7.8840e-02,  2.0037e-01,  4.2229e-02],\n",
       "            [ 7.4267e-02, -1.8248e-01,  7.1119e-02]],\n",
       "  \n",
       "           [[ 9.4027e-02, -1.4259e-01,  9.3704e-02],\n",
       "            [ 1.0551e-01, -1.3152e-01,  1.1948e-01],\n",
       "            [ 1.5848e-01,  1.5036e-02, -6.3056e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-3.4480e-01,  2.4227e-01,  2.2802e-01],\n",
       "            [ 2.1092e-01,  1.8915e-01,  1.5072e-01],\n",
       "            [-1.5162e-01,  1.7502e-01,  1.0856e-01]],\n",
       "  \n",
       "           [[-5.7344e-02, -1.3366e-01,  8.4981e-02],\n",
       "            [-1.9086e-01,  5.1195e-02,  6.1642e-02],\n",
       "            [-1.8153e-02, -6.7430e-02,  4.7210e-02]],\n",
       "  \n",
       "           [[-2.8793e-02,  2.8093e-02, -1.9732e-02],\n",
       "            [-7.5089e-02, -1.3888e-01,  2.7433e-02],\n",
       "            [-2.2986e-02,  4.2635e-04, -8.0297e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-3.9283e-02, -9.0016e-03,  1.3066e-01],\n",
       "            [ 7.0167e-02,  1.6156e-01,  1.6050e-01],\n",
       "            [ 2.3277e-01, -2.2018e-02,  7.2162e-02]],\n",
       "  \n",
       "           [[-1.2229e-01, -2.5055e-02, -3.6937e-02],\n",
       "            [-4.2200e-03,  5.2262e-02, -9.6354e-02],\n",
       "            [-7.2352e-02,  5.4672e-02, -8.8095e-02]],\n",
       "  \n",
       "           [[-3.7626e-01, -7.5517e-02,  1.7402e-02],\n",
       "            [-1.1368e-01,  1.6148e-01,  6.6353e-02],\n",
       "            [-4.7418e-01,  3.0442e-02, -6.9939e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-6.2910e-02, -5.5956e-02,  3.7735e-02],\n",
       "            [ 3.9015e-01,  3.1802e-01,  1.2045e-01],\n",
       "            [-9.3296e-02, -9.5901e-02, -5.1980e-02]],\n",
       "  \n",
       "           [[ 8.1582e-02,  9.5667e-02, -3.9684e-02],\n",
       "            [ 2.5186e-01,  2.6208e-03,  1.0357e-01],\n",
       "            [-3.3984e-02,  1.0683e-01, -3.2740e-02]],\n",
       "  \n",
       "           [[ 6.3161e-02,  1.1120e-01,  1.2096e-01],\n",
       "            [-6.4317e-02, -5.9959e-02, -6.6973e-02],\n",
       "            [ 8.3733e-02,  8.8192e-02,  1.5274e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-9.8568e-02,  1.2242e-01,  9.9914e-02],\n",
       "            [-5.7516e-02, -1.6513e-01, -2.0927e-02],\n",
       "            [-1.9696e-02,  1.5731e-02, -4.0226e-03]],\n",
       "  \n",
       "           [[-6.3065e-02,  4.5746e-02,  8.7850e-02],\n",
       "            [ 6.3830e-02, -9.6035e-02,  5.7099e-02],\n",
       "            [ 7.0019e-02, -4.1728e-02, -4.5837e-02]],\n",
       "  \n",
       "           [[ 1.5212e-01,  1.6412e-01,  1.1373e-01],\n",
       "            [ 1.3781e-01, -1.3459e-01, -2.3944e-02],\n",
       "            [-2.1582e-02,  5.0186e-02, -6.8164e-02]]]], requires_grad=True)),\n",
       " ('conv3.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0819,  0.0382,  0.1652, -0.2021,  0.0231,  0.0122, -0.0270,  0.0902,\n",
       "           0.1306,  0.2616], requires_grad=True))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Seqential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    def forward(self, input):\n",
    "        return self.func(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_train[1:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(lambda x: x.view(-1, 1, 28, 28)),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.squeeze()) #Lambda(lambda x; x.view(x.size(0), -1)))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor .size(0) and .shape[0] are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 10])\n",
      "torch.Size([9, 10])\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "a = model(test)\n",
    "b = model(test).view(model(test).size(0), -1)\n",
    "print(b.shape)\n",
    "print(a.shape)\n",
    "print(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.1328,  0.0005, -0.1004],\n",
       "            [ 0.0945, -0.3170, -0.1246],\n",
       "            [-0.0893, -0.1447, -0.2301]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0631, -0.0827,  0.0161],\n",
       "            [-0.0556,  0.1839,  0.1200],\n",
       "            [-0.2942,  0.0693, -0.2464]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3226, -0.0878, -0.1789],\n",
       "            [ 0.3239, -0.0195, -0.1699],\n",
       "            [-0.1922, -0.1654,  0.0740]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2780,  0.0779,  0.0333],\n",
       "            [ 0.2801,  0.2312,  0.0069],\n",
       "            [-0.2503, -0.1419,  0.1662]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2925, -0.2251,  0.3328],\n",
       "            [ 0.1876,  0.2832, -0.3112],\n",
       "            [ 0.0576, -0.0988,  0.0519]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1421,  0.0082,  0.2727],\n",
       "            [ 0.0749, -0.2818, -0.2175],\n",
       "            [-0.0782,  0.1502,  0.2810]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0944, -0.0837, -0.0681],\n",
       "            [ 0.0265, -0.2777,  0.3070],\n",
       "            [ 0.3281,  0.2186, -0.2434]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2808, -0.1193, -0.0650],\n",
       "            [ 0.1665,  0.2371, -0.0838],\n",
       "            [-0.1710, -0.0349, -0.1610]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2665,  0.0898,  0.1350],\n",
       "            [ 0.1643,  0.1551, -0.3031],\n",
       "            [-0.0751,  0.0246,  0.1576]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1356,  0.1045,  0.0142],\n",
       "            [-0.0726, -0.1092,  0.2715],\n",
       "            [ 0.2732,  0.3282,  0.3282]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2729,  0.2787,  0.1714],\n",
       "            [ 0.0712,  0.1016, -0.1115],\n",
       "            [-0.3239,  0.3025,  0.0250]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2358,  0.2371,  0.1993],\n",
       "            [-0.0854,  0.0900, -0.0088],\n",
       "            [-0.1731,  0.0038,  0.1924]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2582, -0.1575,  0.2190],\n",
       "            [ 0.3210, -0.1084,  0.3010],\n",
       "            [-0.2787, -0.2250, -0.3303]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3139,  0.0482,  0.0816],\n",
       "            [-0.0987, -0.1599,  0.2452],\n",
       "            [ 0.2896, -0.2598, -0.1783]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2206, -0.3294,  0.2468],\n",
       "            [ 0.3032, -0.2341, -0.0581],\n",
       "            [-0.1282,  0.0035,  0.1295]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2955, -0.2116,  0.0111],\n",
       "            [-0.0562, -0.1402,  0.1550],\n",
       "            [-0.2800,  0.2141,  0.1390]]]], requires_grad=True)),\n",
       " ('1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2861, -0.1910,  0.0698,  0.3316,  0.1044, -0.0018,  0.3097, -0.1966,\n",
       "           0.2107, -0.2207, -0.2251,  0.2304, -0.2615, -0.0701, -0.3241, -0.0945],\n",
       "         requires_grad=True)),\n",
       " ('3.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-4.5112e-02,  7.0125e-02,  6.0314e-02],\n",
       "            [ 6.2071e-02, -8.0211e-02,  6.6505e-03],\n",
       "            [ 5.3534e-02, -7.4320e-03,  5.4696e-02]],\n",
       "  \n",
       "           [[ 7.5277e-02,  1.7602e-03,  1.7931e-02],\n",
       "            [-6.0320e-02, -2.3315e-02,  7.1022e-02],\n",
       "            [-1.1925e-02,  7.5762e-04,  7.3322e-02]],\n",
       "  \n",
       "           [[-1.0822e-02, -7.9015e-02, -6.5265e-02],\n",
       "            [-4.8408e-02, -7.5605e-02,  1.1621e-02],\n",
       "            [ 6.1121e-02, -2.4690e-02, -7.4976e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.2804e-02, -4.1336e-02, -8.0116e-03],\n",
       "            [ 2.4030e-03, -3.5259e-02,  5.8825e-02],\n",
       "            [ 2.5116e-02,  4.2463e-02, -5.3105e-02]],\n",
       "  \n",
       "           [[-5.6609e-02,  3.0992e-02,  5.6403e-02],\n",
       "            [ 3.5476e-02,  4.2310e-02,  1.0855e-02],\n",
       "            [ 2.9549e-03,  3.0980e-02, -1.6704e-02]],\n",
       "  \n",
       "           [[-8.2139e-02, -4.0289e-02,  4.0189e-03],\n",
       "            [ 5.1420e-02, -1.5678e-02,  7.7837e-02],\n",
       "            [ 2.0887e-02,  3.8596e-02, -2.4336e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-8.4491e-03, -3.1976e-02, -6.7476e-02],\n",
       "            [-5.7729e-02,  4.7373e-02,  4.4815e-02],\n",
       "            [-6.6369e-02, -6.9664e-02,  1.1130e-02]],\n",
       "  \n",
       "           [[ 4.2485e-03,  4.3610e-03,  3.3989e-02],\n",
       "            [-9.2362e-03,  3.2458e-03,  8.2515e-02],\n",
       "            [-3.5362e-02,  1.9799e-02,  8.2049e-03]],\n",
       "  \n",
       "           [[ 8.3987e-03, -8.8512e-03,  3.9388e-02],\n",
       "            [ 6.6079e-02, -2.3384e-02,  2.9978e-02],\n",
       "            [-5.5884e-02,  5.9175e-02, -7.9442e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-2.3842e-02, -3.6366e-02,  6.2405e-02],\n",
       "            [-6.5458e-02,  4.9793e-02,  6.5397e-02],\n",
       "            [-4.6787e-02,  5.4896e-02,  7.1824e-02]],\n",
       "  \n",
       "           [[ 2.0850e-02, -7.6666e-02,  7.1318e-02],\n",
       "            [ 1.1048e-02,  2.0544e-02, -8.3314e-04],\n",
       "            [-3.5861e-02,  1.0005e-02,  4.1338e-02]],\n",
       "  \n",
       "           [[ 2.5645e-02,  6.5738e-02, -3.7186e-02],\n",
       "            [ 2.4464e-02, -4.8815e-02, -1.3022e-02],\n",
       "            [-5.8263e-02, -2.1701e-02,  7.0368e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 6.1360e-02, -4.2601e-02,  6.6458e-02],\n",
       "            [-3.2693e-02,  2.5865e-02,  4.3601e-02],\n",
       "            [-7.8292e-02,  4.9859e-03, -5.8893e-02]],\n",
       "  \n",
       "           [[ 7.3248e-02, -6.5928e-02,  5.4316e-02],\n",
       "            [-7.1461e-02,  1.4835e-02, -1.2437e-02],\n",
       "            [ 1.9615e-02,  6.9156e-02,  6.2423e-03]],\n",
       "  \n",
       "           [[ 5.3140e-02,  1.8982e-02,  6.0142e-04],\n",
       "            [ 4.3560e-02,  5.9896e-02,  9.4129e-03],\n",
       "            [ 7.2651e-02,  2.5924e-02, -7.9922e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 7.8166e-02, -4.0995e-02, -6.9460e-02],\n",
       "            [ 2.4412e-02, -1.0820e-02,  3.6558e-02],\n",
       "            [-3.0535e-02,  6.2542e-02, -2.4857e-02]],\n",
       "  \n",
       "           [[-2.2391e-02,  2.2392e-04,  2.6019e-02],\n",
       "            [ 6.5741e-02, -6.2527e-02, -3.3316e-02],\n",
       "            [ 4.7841e-02, -8.0814e-02, -7.1191e-02]],\n",
       "  \n",
       "           [[ 6.0336e-02,  4.6485e-03, -1.9609e-02],\n",
       "            [-5.6226e-02, -2.3514e-02, -2.9814e-02],\n",
       "            [ 6.4789e-02,  6.0643e-02,  7.0554e-02]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 6.2019e-02, -2.2410e-02, -5.8151e-02],\n",
       "            [-1.3809e-02, -2.6023e-02, -5.8832e-02],\n",
       "            [ 2.1624e-02,  2.6731e-02,  2.3020e-03]],\n",
       "  \n",
       "           [[ 7.8015e-04,  3.4796e-02,  2.5155e-02],\n",
       "            [ 1.1998e-02,  4.2714e-02, -2.3399e-02],\n",
       "            [-1.4225e-02,  2.1219e-02,  3.5551e-02]],\n",
       "  \n",
       "           [[ 3.9312e-02,  8.3863e-03,  4.3752e-02],\n",
       "            [-6.2494e-02,  6.9437e-02,  9.6621e-03],\n",
       "            [-6.5882e-04,  7.5441e-02,  5.9637e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-6.7849e-02,  4.0366e-03,  8.2319e-02],\n",
       "            [-5.0010e-02, -2.6083e-02,  6.0039e-03],\n",
       "            [ 8.0556e-02,  3.7300e-02, -1.9002e-02]],\n",
       "  \n",
       "           [[-8.7743e-03, -2.3780e-02, -6.9009e-02],\n",
       "            [ 7.5142e-02, -2.8303e-02,  4.6785e-02],\n",
       "            [ 8.2509e-02, -3.9368e-02,  6.2593e-02]],\n",
       "  \n",
       "           [[-3.5499e-02, -3.4933e-02, -6.7186e-02],\n",
       "            [ 5.9989e-02,  4.6407e-02,  4.9135e-02],\n",
       "            [-7.9271e-02, -3.2091e-02,  6.3355e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 8.1736e-02,  2.8829e-02, -1.5534e-02],\n",
       "            [-7.2084e-02, -4.2218e-02, -1.2876e-02],\n",
       "            [-4.3581e-02,  6.3644e-02, -4.5364e-02]],\n",
       "  \n",
       "           [[-7.5681e-02,  5.2086e-02, -2.3185e-02],\n",
       "            [-3.4938e-02,  7.6020e-02, -3.6214e-02],\n",
       "            [ 2.1662e-02,  5.3093e-03,  7.9591e-02]],\n",
       "  \n",
       "           [[ 7.5324e-02,  4.1784e-02,  7.9577e-02],\n",
       "            [-2.1147e-02, -3.4980e-02, -7.0163e-03],\n",
       "            [-2.3737e-02,  7.0542e-02,  5.2011e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-4.3399e-02, -1.5107e-02,  4.2263e-02],\n",
       "            [ 1.9643e-02, -4.7746e-02,  5.6161e-02],\n",
       "            [ 6.2550e-02, -6.5572e-02,  5.0283e-03]],\n",
       "  \n",
       "           [[ 2.9737e-02,  4.1595e-02,  5.8286e-02],\n",
       "            [ 3.8282e-02,  2.1500e-02, -3.6678e-02],\n",
       "            [ 7.7786e-02, -4.7977e-02,  5.5791e-02]],\n",
       "  \n",
       "           [[ 7.9791e-02,  6.4043e-02,  5.3465e-03],\n",
       "            [ 7.5680e-03,  8.0711e-02, -3.4601e-02],\n",
       "            [-5.3684e-02,  6.1475e-02,  7.4122e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 4.6238e-03,  5.8768e-02, -5.8497e-02],\n",
       "            [ 6.9992e-02,  4.5448e-02, -5.0474e-02],\n",
       "            [-4.9829e-02, -3.0915e-02, -1.6321e-03]],\n",
       "  \n",
       "           [[-6.5545e-02, -7.5052e-02, -2.0708e-03],\n",
       "            [-6.5403e-02,  6.4323e-02,  6.5248e-02],\n",
       "            [ 5.0806e-02,  9.9411e-05, -6.7754e-02]],\n",
       "  \n",
       "           [[ 2.0902e-02,  6.6734e-02, -5.0698e-02],\n",
       "            [ 4.4011e-02, -3.5985e-02, -6.8058e-02],\n",
       "            [ 6.1863e-02, -6.2905e-02, -2.8427e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-8.2315e-02,  7.8696e-02,  6.5047e-02],\n",
       "            [ 4.5092e-02,  5.5834e-02,  7.8402e-02],\n",
       "            [-7.3593e-02, -3.8700e-02, -1.9529e-02]],\n",
       "  \n",
       "           [[-6.3153e-03,  5.1195e-02,  2.6115e-02],\n",
       "            [-1.8216e-02,  7.4320e-02,  2.5745e-03],\n",
       "            [-5.9594e-02,  1.8764e-02,  3.5636e-02]],\n",
       "  \n",
       "           [[-3.9166e-02, -7.3283e-02,  2.8393e-02],\n",
       "            [ 7.8121e-02, -5.6207e-02,  7.0918e-02],\n",
       "            [ 6.2911e-02, -5.6209e-02,  4.4580e-02]]]], requires_grad=True)),\n",
       " ('3.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0059, -0.0696, -0.0072,  0.0547, -0.0108,  0.0422, -0.0011, -0.0433,\n",
       "           0.0301,  0.0277, -0.0530,  0.0293,  0.0722,  0.0614,  0.0224, -0.0551],\n",
       "         requires_grad=True)),\n",
       " ('5.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0111, -0.0234,  0.0527],\n",
       "            [-0.0543,  0.0204,  0.0234],\n",
       "            [ 0.0252, -0.0159,  0.0558]],\n",
       "  \n",
       "           [[-0.0681,  0.0689,  0.0531],\n",
       "            [-0.0595, -0.0637, -0.0711],\n",
       "            [ 0.0380, -0.0686,  0.0477]],\n",
       "  \n",
       "           [[-0.0045, -0.0324,  0.0601],\n",
       "            [-0.0641, -0.0294,  0.0441],\n",
       "            [ 0.0634, -0.0275,  0.0451]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0811,  0.0423, -0.0424],\n",
       "            [-0.0074, -0.0426, -0.0568],\n",
       "            [-0.0094,  0.0433,  0.0313]],\n",
       "  \n",
       "           [[ 0.0018, -0.0119,  0.0643],\n",
       "            [-0.0270, -0.0808,  0.0383],\n",
       "            [ 0.0226, -0.0583,  0.0144]],\n",
       "  \n",
       "           [[-0.0663,  0.0630,  0.0806],\n",
       "            [ 0.0764, -0.0814,  0.0613],\n",
       "            [ 0.0093,  0.0581, -0.0374]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0418,  0.0458, -0.0735],\n",
       "            [-0.0458,  0.0338, -0.0383],\n",
       "            [-0.0572, -0.0756,  0.0313]],\n",
       "  \n",
       "           [[-0.0754,  0.0173, -0.0095],\n",
       "            [ 0.0249, -0.0692,  0.0403],\n",
       "            [ 0.0712,  0.0647, -0.0253]],\n",
       "  \n",
       "           [[ 0.0241,  0.0017, -0.0215],\n",
       "            [ 0.0050, -0.0114,  0.0032],\n",
       "            [ 0.0605, -0.0708,  0.0182]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0284, -0.0610,  0.0139],\n",
       "            [ 0.0158,  0.0678, -0.0610],\n",
       "            [ 0.0068,  0.0091, -0.0053]],\n",
       "  \n",
       "           [[ 0.0710,  0.0077,  0.0298],\n",
       "            [-0.0457,  0.0248,  0.0245],\n",
       "            [ 0.0031, -0.0037, -0.0338]],\n",
       "  \n",
       "           [[ 0.0386, -0.0696, -0.0061],\n",
       "            [ 0.0538,  0.0257,  0.0569],\n",
       "            [ 0.0174,  0.0744,  0.0169]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0456, -0.0091, -0.0680],\n",
       "            [-0.0650, -0.0651,  0.0184],\n",
       "            [-0.0428,  0.0095, -0.0470]],\n",
       "  \n",
       "           [[-0.0581, -0.0173, -0.0769],\n",
       "            [-0.0674, -0.0602,  0.0695],\n",
       "            [ 0.0128, -0.0514,  0.0254]],\n",
       "  \n",
       "           [[-0.0777, -0.0338,  0.0332],\n",
       "            [ 0.0485,  0.0209,  0.0537],\n",
       "            [-0.0407, -0.0803, -0.0315]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0073,  0.0063,  0.0224],\n",
       "            [ 0.0038,  0.0450, -0.0075],\n",
       "            [-0.0617,  0.0012,  0.0238]],\n",
       "  \n",
       "           [[-0.0145, -0.0448,  0.0237],\n",
       "            [ 0.0057, -0.0716, -0.0618],\n",
       "            [ 0.0607,  0.0239,  0.0827]],\n",
       "  \n",
       "           [[-0.0471,  0.0260,  0.0668],\n",
       "            [ 0.0208, -0.0497,  0.0659],\n",
       "            [ 0.0054,  0.0456,  0.0111]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.0677,  0.0772, -0.0306],\n",
       "            [ 0.0181, -0.0594,  0.0441],\n",
       "            [ 0.0252, -0.0814,  0.0604]],\n",
       "  \n",
       "           [[-0.0438,  0.0100, -0.0361],\n",
       "            [ 0.0689,  0.0164, -0.0588],\n",
       "            [-0.0417, -0.0321,  0.0104]],\n",
       "  \n",
       "           [[-0.0505, -0.0234, -0.0109],\n",
       "            [-0.0720, -0.0644,  0.0456],\n",
       "            [ 0.0468, -0.0493,  0.0209]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0719, -0.0540, -0.0310],\n",
       "            [-0.0305, -0.0110, -0.0074],\n",
       "            [ 0.0209, -0.0268,  0.0234]],\n",
       "  \n",
       "           [[ 0.0426, -0.0489, -0.0022],\n",
       "            [ 0.0614, -0.0014,  0.0062],\n",
       "            [-0.0760,  0.0414, -0.0567]],\n",
       "  \n",
       "           [[-0.0706,  0.0571,  0.0382],\n",
       "            [ 0.0481,  0.0797, -0.0124],\n",
       "            [ 0.0606,  0.0078,  0.0450]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0117,  0.0631,  0.0333],\n",
       "            [ 0.0413, -0.0294,  0.0671],\n",
       "            [-0.0661, -0.0406, -0.0340]],\n",
       "  \n",
       "           [[-0.0615, -0.0251,  0.0724],\n",
       "            [-0.0435,  0.0591, -0.0474],\n",
       "            [-0.0291, -0.0792, -0.0650]],\n",
       "  \n",
       "           [[-0.0401, -0.0761,  0.0184],\n",
       "            [ 0.0320, -0.0128,  0.0388],\n",
       "            [-0.0750, -0.0344,  0.0803]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0811, -0.0389,  0.0353],\n",
       "            [-0.0249, -0.0349,  0.0004],\n",
       "            [-0.0263, -0.0733,  0.0508]],\n",
       "  \n",
       "           [[-0.0162, -0.0721, -0.0021],\n",
       "            [-0.0282,  0.0433,  0.0400],\n",
       "            [ 0.0330,  0.0537,  0.0120]],\n",
       "  \n",
       "           [[ 0.0684,  0.0158,  0.0278],\n",
       "            [ 0.0799, -0.0229,  0.0314],\n",
       "            [-0.0187, -0.0027,  0.0791]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0033, -0.0673,  0.0331],\n",
       "            [ 0.0320,  0.0240,  0.0009],\n",
       "            [ 0.0322, -0.0387,  0.0711]],\n",
       "  \n",
       "           [[-0.0241,  0.0523,  0.0016],\n",
       "            [-0.0346, -0.0237, -0.0566],\n",
       "            [ 0.0479,  0.0612,  0.0125]],\n",
       "  \n",
       "           [[ 0.0700, -0.0221, -0.0039],\n",
       "            [-0.0180,  0.0085,  0.0674],\n",
       "            [-0.0801, -0.0511,  0.0775]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0108, -0.0021, -0.0472],\n",
       "            [-0.0056, -0.0606,  0.0340],\n",
       "            [ 0.0765,  0.0109, -0.0470]],\n",
       "  \n",
       "           [[-0.0255, -0.0642,  0.0150],\n",
       "            [-0.0249,  0.0281, -0.0787],\n",
       "            [-0.0324, -0.0232,  0.0077]],\n",
       "  \n",
       "           [[-0.0590, -0.0299, -0.0543],\n",
       "            [-0.0425,  0.0591,  0.0699],\n",
       "            [-0.0738, -0.0531, -0.0513]]]], requires_grad=True)),\n",
       " ('5.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0658, -0.0209, -0.0543,  0.0381,  0.0647, -0.0111, -0.0033, -0.0492,\n",
       "          -0.0206, -0.0045], requires_grad=True))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.478 accuracy=0.859\n",
      "Epoch 1: loss=0.369 accuracy=0.892\n"
     ]
    }
   ],
   "source": [
    "model.apply(initialize_weight1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n",
    "train(model, optimizer=optimizer, dataloaders=Dataloaders, num_epochs=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of GPUs for learning\n",
    "- We should be careful if our all sets for deep learning are existing on GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ryotok/Documents/ML_DL/machine-learning-initial/machine_learning_sum.ipynb Cell 76\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ryotok/Documents/ML_DL/machine-learning-initial/machine_learning_sum.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# move our model to the device\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ryotok/Documents/ML_DL/machine-learning-initial/machine_learning_sum.ipynb#Y135sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlml/lib/python3.10/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlml/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlml/lib/python3.10/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/dlml/lib/python3.10/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# move our model to the device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataloaders = {}\n",
    "Dataloaders['train'] = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "Dataloaders['val'] = DataLoader(val_set, batch_size=16, shuffle=False)\n",
    "Dataloaders['test'] = DataLoader(test_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloaders, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # training\n",
    "        model.train()\n",
    "        for input, target in dataloaders['train']:\n",
    "            input, target = input.to(device), target.to(device)\n",
    "\n",
    "            pred = model(input)\n",
    "            loss = F.cross_entropy(pred, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        loss = 0\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "\n",
    "        for input, target in dataloaders['val']:\n",
    "            input, target = input.to(device), target.to(device)\n",
    "\n",
    "            pred = model(input)\n",
    "            loss += F.cross_entropy(pred, target)\n",
    "\n",
    "            n_correct += (pred.argmax(-1) == target).sum()\n",
    "            n_samples += len(dataloaders['val'])\n",
    "\n",
    "        avg_loss = loss/len(dataloaders['val'])\n",
    "        accuracy = n_correct/n_samples\n",
    "\n",
    "        print(f\"Epoch {epoch}: loss={avg_loss :.3f} accuracy={accuracy :.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.646 accuracy=0.034\n",
      "Epoch 1: loss=0.399 accuracy=0.038\n"
     ]
    }
   ],
   "source": [
    "model.apply(initialize_weight1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "\n",
    "train(model, optimizer=optimizer, dataloaders=Dataloaders, num_epochs=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "- runtime: Drop the input (set weight to zero) = Drop neurons randomly by drop out rate (p=self.p)\n",
    "    - Scale the not dropped neurons output by $\\frac{1}{1-p}$\n",
    "        - To conserve input mean\n",
    "- validation: Use all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_mean: \n",
      "-0.029329748824238777\n",
      "\n",
      "dropped_out_mean:\n",
      "0.01352981198579073\n",
      "\n",
      "is_closed_enough?:  False\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(10, 10)\n",
    "print(\"input_mean: \")\n",
    "input_mean=input.mean()\n",
    "print(input_mean.item())\n",
    "\n",
    "mask = torch.zeros_like(input)\n",
    "p = 0.2\n",
    "mask.bernoulli_(p)\n",
    "scale = 1 / (1-p)\n",
    "droped_out = scale * mask * input\n",
    "print()\n",
    "print(\"dropped_out_mean:\")\n",
    "droped_out_mean=droped_out.mean()\n",
    "print(droped_out_mean.item())\n",
    "\n",
    "print()\n",
    "#chenck the conservation of the mean\n",
    "print(\"is_closed_enough?: \", np.isclose(input_mean.item(), droped_out_mean.item(), atol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    # p:float, drop probability\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input:Pytorch tensor, arbitrary shape\n",
    "        Returns:\n",
    "            Pytorch tensor, same shape as input (Droped out)\n",
    "        \"\"\"\n",
    "            \n",
    "        if self.training:\n",
    "            mask = torch.zeros_like(input)\n",
    "            mask.bernoulli_(1-self.p) # set 1 to the not dropped input\n",
    "            scaling = 1 / (1 - self.p)\n",
    "            dropped_out = scaling * input * mask\n",
    "        return dropped_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003859536722302437\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#Test dropout\n",
    "test = torch.randn(10_000)\n",
    "dropout = Dropout(0.5)\n",
    "test_droped_out = dropout(test)\n",
    "\n",
    "# Obtain item in the tensor\n",
    "print(test.mean().item())\n",
    "print(type(test.mean().item()))\n",
    "\n",
    "assert np.isclose(test.mean().item(), test_droped_out.mean().item(), atol=1e-2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization\n",
    "- Batch normalization is a trick to obtain smooth loss landscape and improve training by preserving the variance of input as much as possible\n",
    "\n",
    "- It is defined as the funciton\n",
    "    $$y=\\frac{x-\\mu_x}{\\sigma_x + \\epsilon} \\cdot \\gamma + \\beta$$\n",
    "    - $\\mu_x$: mean of input over the dimension c\n",
    "    - $\\sigma_x$: standard deviation(squareroot of variance) of input over the dimension c\n",
    "    - $\\epsilon$: numerical stability helper\n",
    "    - $\\gamma$: learnable paramter to undo the normalization (=>$\\sigma_x$)\n",
    "    - $\\beta$: learnable paramter to undo the normalization (=>$\\mu_x$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4194, -0.5411,  0.5405,  0.2984, -0.1384, -2.3622, -0.5054, -1.2274,\n",
      "         2.3203,  0.9792])\n",
      "tensor([-0.4194, -0.5411,  0.5405,  0.2984, -0.1384, -2.3622, -0.5054, -1.2274,\n",
      "         2.3203,  0.9792])\n"
     ]
    }
   ],
   "source": [
    "# elemetn-wise multiplication\n",
    "# Since the gamma and beta are having only num_features elements, \n",
    "# we need to add dimention to N and L\n",
    "num_features = 10\n",
    "dummy_gamma=torch.randn(num_features)\n",
    "print(dummy_gamma)\n",
    "augmented=dummy_gamma[None, :, None]\n",
    "print(augmented[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    \"\"\" \n",
    "    Only uses batch statistics (no running mean for evaluation).\n",
    "    Batch statistics are calculated for a single dimension (*input features)\n",
    "    Gamma is initialized as 1, beta as 0\n",
    "\n",
    "    Args: num_features: number of feature to calculate batch statistics for.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Model freely undo the normalization.\n",
    "        Complete-undo brings\n",
    "            Gamma -> standard deviation (=square root of the variance)\n",
    "            Beta -> mean of input\n",
    "        \"\"\"\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Batch normalization over the dimension C of (N, C, L)\n",
    "\n",
    "        Args:\n",
    "            input: Pytorch tensor, shape[N, C, L]\n",
    "            N: number of minibatch samples\n",
    "            C: number of channels (input's dimension)\n",
    "            L: shape of the one channel\n",
    "                -RGB image: L=(H, W)\n",
    "        Return:\n",
    "            Pytorch tensor, same shape as input\n",
    "        \"\"\"\n",
    "\n",
    "        eps = 1e-5 #helper for numerical stability\n",
    "\n",
    "        aggregate_dims = [0, 2]\n",
    "        mean = torch.mean(input, dim=aggregate_dims, keepdim=True)\n",
    "        std = torch.std(input, dim=aggregate_dims, keepdim=True)\n",
    "\n",
    "        input_normalized=(input-mean) / (std + eps)\n",
    "        return self.gamma[None, :, None] * input_normalized + self.beta[None, :, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batch normalization\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "test = torch.randn(8, 2, 4)\n",
    "\n",
    "b1 = BatchNorm(2)\n",
    "test_b1 = b1(test)\n",
    "\n",
    "# nn.BatchNorm1d\n",
    "    # affine\n",
    "    #   True >this module has leranable parameter\n",
    "    # track_running_stats\n",
    "    #   True >track running mean and standard deviation\n",
    "\n",
    "b2 = nn.BatchNorm1d(2, affine=False, track_running_stats=False)\n",
    "test_b2 = b2(test)\n",
    "\n",
    "# torch.allclose \n",
    "    # checks if all input and other satisfy the condition\n",
    "    # elementwise, for all elements of input and other\n",
    "    # rtol > relattive tolerance\n",
    "    # atol > absolute tolerance \n",
    "assert torch.allclose(test_b1, test_b2, rtol=2*1e-2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet\n",
    "- Resnet is the first network which is introduced residual connections\n",
    "- Skip connection can solve problems such as vanishing and exploding gradients as the network gets deeper and deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func=func\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the stride is more than 1 or the in_channels is not equal to out_channels, we need to modify the shape of the input to add the second convolution output and before the final relu activation.\n",
    "\n",
    "In this case, we should care the stride size and the subtraction between out_channel and in_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n",
      "torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "stride = 2\n",
    "x = torch.randn(1, 1, 4, 4)\n",
    "print(x.shape)\n",
    "_x=x[:, :, ::stride, ::stride]\n",
    "print(_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtraction 16\n",
      "original channel 1\n",
      "torch.Size([1, 17, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "out_cha=32\n",
    "in_cha=16\n",
    "print(\"subtraction\", out_cha-in_cha)\n",
    "print(\"original channel\", x.shape[1])\n",
    "\n",
    "# F.pad configuration\n",
    "# padding setting = (padding_left, right, top, bottom, front, back)\n",
    "\n",
    "padded_inpput = F.pad(_x, (0, 0, 0, 0, 0, out_cha-in_cha), mode=\"constant\", value=0) \n",
    "print(padded_inpput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The residual block used by ResNet\n",
    "\n",
    "    Args:\n",
    "        in_channels: The number of channels (feature map) of the incoming embedding\n",
    "        out_channels: The number of channels after the first convolution\n",
    "        stride: Stride size of th first convolution, used for downsampling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        if stride > 1 or in_channels != out_channels:\n",
    "            #Add strides in the skip connection and zeros for the new channels\n",
    "            self.skip = Lambda(lambda x: F.pad(x[:, :, ::stride, ::stride],\n",
    "             (0,0,0,0,0,out_channels - in_channels), mode=\"constant\", value=0))\n",
    "        else:\n",
    "            self.skip = nn.Sequential()\n",
    "\n",
    "        self.conv1=nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # bias term in the convolution layer will be erased by the batch-normalization\n",
    "        self.conv2=nn.Conv2d(out_channels, out_channels, kernel_size=3, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = F.relu(self.bn1(self.conv1(input)))\n",
    "        x2 = self.bn2(self.conv2(x1))\n",
    "        return F.relu(x2 + self.skip(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualStack(nn.Module):\n",
    "    \"\"\"\n",
    "    A stack of residual blocks\n",
    "\n",
    "    Args:\n",
    "        in_channels: The number of channels of the incomming embedding\n",
    "        out_channels: The number of channels of the outgoing embedding\n",
    "        stride: Stride size a the first convolution later for the downsampling\n",
    "        num_blocks: Number of residual blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, num_blocks):\n",
    "        super().__init__()\n",
    "        blocks = [ResidualBlock(in_channels, out_channels, stride=stride)]\n",
    "        for _ in range(num_blocks-1):\n",
    "            blocks.append(ResidualBlock(out_channels, out_channels))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Structure\n",
    "- a covolition latyer is always containing\n",
    "    - Convolution layer\n",
    "    - Batch Normalization\n",
    "    - ReLU activation\n",
    "- The each residual block has two comvolution layer with 1 skip connection\n",
    "- We should __squeeze__ the final output to feed it to the fully-connected(dense) layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Architectures\n",
    "- Args:\n",
    "    - input: 32x32 images\n",
    "    - Per-pixel mean subtracted\n",
    "1. 3x3 Conv layer (input_cha=3, out cha=16)\n",
    "    - Batch\n",
    "    - ReLU activation\n",
    "2. __SAME__ Residual stack (num_blocks = n, input_cha=16, out_channel=16)\n",
    "    - Residual block (1st, stride=1)\n",
    "        - 3x3 Same Convolution (Spacial reduction: 32->32)\n",
    "        - Batch\n",
    "        - ReLU\n",
    "    - Residual block (2st-n)\n",
    "        - 3x3 Same Convolution\n",
    "        - Batch\n",
    "        - ReLU\n",
    "3. __VALID__ Residual stach (num_blocks=n, input_cha=16, out_cha=32)\n",
    "    - Residual block (1st, strider=2)\n",
    "        - 3x3 Valid Convolution (Spacial reduction: 32->16)\n",
    "        - Batch\n",
    "        - ReLU\n",
    "    - Residual block (2st-n)\n",
    "        - 3x3 Same Convolution\n",
    "        - Batch\n",
    "        - ReLU\n",
    "4. __VALID__ Residual stach (num_blocks=n, input_cha=32, out_cha=64)\n",
    "    - Residual block (1st, strider=2)\n",
    "        - 3x3 Valid Convolution (Spacial reduction: 16->8)\n",
    "        - Batch\n",
    "        - ReLU\n",
    "    - Residual block (2st-n)\n",
    "        - 3x3 Same Convolution\n",
    "        - Batch\n",
    "        - ReLU\n",
    "5. Average Pooling to reduce spacial dimension from 8x8 to 1x1 per channel\n",
    "6. Lambda squeeze the output and flatten\n",
    "7. Fully connected NN (input_dim=64, out_dim=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "num_classes = 10\n",
    "\n",
    "resnet = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(num_features=16),\n",
    "    nn.ReLU(),\n",
    "    ResidualStack(in_channels=16, out_channels=16, stride=1, num_blocks=n),\n",
    "    ResidualStack(in_channels=16, out_channels=32, stride=2, num_blocks=n),\n",
    "    ResidualStack(in_channels=32, out_channels=64, stride=2, num_blocks=n),\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    Lambda(lambda x: x.squeeze()),\n",
    "    nn.Linear(in_features=64, out_features=num_classes)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the module(layer) weight and bias\n",
    "- We need to initialize the weights of our model appropriately\n",
    "- module.weight, module.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): ResidualStack(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): ResidualStack(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (skip): Lambda()\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): ResidualStack(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (skip): Lambda()\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (skip): Sequential()\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): AdaptiveAvgPool2d(output_size=1)\n",
       "  (7): Lambda()\n",
       "  (8): Linear(in_features=64, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize_weight_Resnet(module): ##intilalize each layer(module)\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        nn.init.constant_(module.weight, 1) #initialize gamma with 1\n",
    "        nn.init.constant_(module.bias, 0) #initialize beta with 0\n",
    "\n",
    "resnet.apply(initialize_weight_Resnet)\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of resnet\n",
    "### Data loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define data download class from the dataset server\n",
    "- Define the transformation\n",
    "    - mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]\n",
    "    - Use precomputed mean and standard deviation of respective channel\n",
    "- Down load the data using the transmormation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Subset(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"\n",
    "    Ger a subset of the CIFAR10 dataset provided thougth torch.vision\n",
    "    return the Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, idx=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        if idx is None:\n",
    "            return\n",
    "        \n",
    "        self.data=self.data[idx]\n",
    "        target_np = np.array(self.targets)\n",
    "        self.targets=target_np[idx].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation in precomputing\n",
    "- We need to make the model be robust to wide variety of the transformation\n",
    "- Usually a real-world image does not contain the full-body image of object\n",
    "- Cropping is good data augmentation for the occulusion\n",
    "- Horizonfilp is good data augmentation foe the robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, 4),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = CIFAR10Subset(root='./data', train=True, idx=range(50_000), download=True, transform=rt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary `torch`\n",
    "- `torch.tensor`: PyTorch tensors work like numpy arrays, but can remember gradients and be sent to GPUs\n",
    "- `torch.nn`\n",
    "    - `torch.nn.funciotnal` : Provides various useful functions (non stateful) for training neural networks, e.g. activation functions and loss functions\n",
    "    - `nn.Module` : Subclass from this to create a callable that acts like a function, but can remember stat. It knows what parameters and submodules it contains and privides various functionality based on that\n",
    "    - `nn.Parameters` : Wraps a tensor and tells the containing Module that it needs updating dusring backpropagation\n",
    "    - `torch.nn` : Many useful layers are already implemented in this library e.g. nn.Linear, nn.Conv2d\n",
    "    - `nn.Sequential` : Provides an easy way of defining purely stacked modules\n",
    "\n",
    "- `torch.optim` : Optimizers such as SGD or Adam, which let you easily update and train the paramters inside the passed model\n",
    "\n",
    "- `Dataset(Tensordataset)` : interface for data using only the __len__ and __getitem__ functions. Tensors can be converetd into a Dataset by using Tensor Dataset\n",
    "\n",
    "- `DataLoader` : Takes any Dataset and provides an iterator for returning mini-bathces with various advanced functionality\n",
    " \n",
    "- `GPU` : To use your GPU you need to move your model and each mini-batch to your GPU using __.to(devide)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6b7a25b8b2426eb550c8146811605d9bdb61f23d99ada7f1c3a4f71b608de8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
